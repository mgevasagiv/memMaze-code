{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T23:57:42.610049Z",
     "start_time": "2025-12-10T23:57:42.038356Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------------\n",
    "# Positional Encoding\n",
    "# -------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "# -------------------------------\n",
    "# Region Embedding (CNN + Class Token)\n",
    "# -------------------------------\n",
    "class RegionEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels, embed_dim, patch_size):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, embed_dim, kernel_size=(1, patch_size), stride=(1, patch_size))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels, electrodes, time_bins)\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv(x)  # (batch, embed_dim, electrodes, time_bins_patch)\n",
    "        x = x.flatten(2).transpose(1, 2)  # (batch, num_patches, embed_dim)\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # (batch, 1, embed_dim)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)  # prepend class token\n",
    "        x = self.pos_encoder(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# Multi-Head Self-Attention Block\n",
    "# -------------------------------\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 2*embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2*embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, kv=None):\n",
    "        # x: query (batch, seq_len, embed_dim)\n",
    "        # kv: key/value (batch, seq_len_kv, embed_dim) for cross-attention\n",
    "        if kv is None:\n",
    "            kv = x\n",
    "        attn_out, _ = self.attn(x, kv, kv)\n",
    "        x = self.norm(x + attn_out)\n",
    "        x = self.norm(x + self.ff(x))\n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# Region-wise Self-Attention (RSA)\n",
    "# -------------------------------\n",
    "class RSA(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, depth):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([MultiHeadAttention(embed_dim, num_heads) for _ in range(depth)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, num_patches+1, embed_dim)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        # return only the class token\n",
    "        return x[:, 0, :]  # shape: (batch, embed_dim)\n",
    "\n",
    "# -------------------------------\n",
    "# Cross-Region Attention (CRA)\n",
    "# -------------------------------\n",
    "class CRA(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, depth):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([MultiHeadAttention(embed_dim, num_heads) for _ in range(depth)])\n",
    "\n",
    "    def forward(self, class_tokens):\n",
    "        # class_tokens: list of class tokens from each region, each shape (batch, embed_dim)\n",
    "        x = torch.stack(class_tokens, dim=1)  # (batch, num_regions, embed_dim)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return [x[:, i, :] for i in range(x.size(1))]  # return list of updated tokens per region\n",
    "\n",
    "# -------------------------------\n",
    "# Combiner\n",
    "# -------------------------------\n",
    "class Combiner(nn.Module):\n",
    "    def forward(self, class_tokens):\n",
    "        # average all region tokens\n",
    "        x = torch.stack(class_tokens, dim=0).mean(dim=0)  # (batch, embed_dim)\n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# Full Model\n",
    "# -------------------------------\n",
    "class IEegTransformer(nn.Module):\n",
    "    def __init__(self, regions_config, embed_dim=396, num_heads=6, depth_rsa=6, depth_cra=6, patch_size=5, num_classes=8):\n",
    "        \"\"\"\n",
    "        regions_config: list of tuples (in_channels, num_electrodes)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_regions = len(regions_config)\n",
    "        self.region_embeddings = nn.ModuleList([RegionEmbedding(in_ch, embed_dim, patch_size)\n",
    "                                                for in_ch, _ in regions_config])\n",
    "        self.rsa = nn.ModuleList([RSA(embed_dim, num_heads, depth_rsa) for _ in regions_config])\n",
    "        self.cra = CRA(embed_dim, num_heads, depth_cra)\n",
    "        self.combiner = Combiner()\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_list):\n",
    "        \"\"\"\n",
    "        x_list: list of tensors per region, each shape (batch, channels, electrodes, time_bins)\n",
    "        \"\"\"\n",
    "        region_tokens = []\n",
    "        for i in range(self.num_regions):\n",
    "            x = self.region_embeddings[i](x_list[i])\n",
    "            token = self.rsa[i](x)  # RSA output class token\n",
    "            region_tokens.append(token)\n",
    "        region_tokens = self.cra(region_tokens)  # CRA updates each region token\n",
    "        unified_repr = self.combiner(region_tokens)  # average over regions\n",
    "        out = self.classifier(unified_repr)  # logits for 8 concepts\n",
    "        return torch.sigmoid(out)  # BCE probabilities\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnn\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mF\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------\n",
    "# Example Usage\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 4\n",
    "    time_bins = 50\n",
    "    regions_config = [(2, 8), (2, 8), (2, 8)]  # example 3 regions with 8 electrodes each, 2 channels per region\n",
    "\n",
    "    # random input tensors per region\n",
    "    x_list = [torch.randn(batch_size, in_ch, n_e, time_bins) for in_ch, n_e in regions_config]\n",
    "\n",
    "    model = IEegTransformer(regions_config)\n",
    "    output = model(x_list)\n",
    "    print(output.shape)  # (batch_size, 8)\n"
   ],
   "id": "37897c154aa5d234"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
